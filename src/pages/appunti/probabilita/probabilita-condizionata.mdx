---
capitolo: 1.3
esercizi: "prova"
---

# Probabilit√† condizionata

Vogliamo calcolare la probabilit√† che tengano conto di _informazioni parziali_ sull'esito dell'esperimento.

Cosa si intende con _informazioni parziali_. Per spiegarlo facciamo un esperimento:

_lancio 2 dadi_ (con il concetto che posso distinguerli, per esempio uno √® rosso o e blu. In questo caso scegliamo l'ordine)

Cosa vuol dire informazioni parziali?<br/>
In questo caso potrebbe essere: "la somma fa 9"

$\Omega = \{ (i,j) \}$ con `i` = lancio il primo dado, `j` = lancio il secondo. $i,j = \{ 1,2,3,4,5,6 \}$

$\#\Omega = 36$

$\mathbb P(A) = \frac{\#A}{\#\Omega} = \frac{4}{36} = \frac{1}{9}$

$A = \{ (4,5), (5,4), (3,6), (6,3) \}$

---

$B =$ "il primo dado ha dato 6"

$\mathbb P(B) = \frac{6}{36} = \frac{1}{6}$

---

Ora immaginiamo che un omino ci dica che vedendo che con il primo esca 6. Ora quante probabilit√† ci sono che la sua somma faccia 9?

Le informazioni parziali delle _condizioni_ nel quale noi dobbiamo creare una nuova $\mathbb P$. Come notazione per indicare la nuova $\mathbb P$ si indica con $\mathbb P(A | B)$ che significa: "la $\mathbb P$ dato $B$". Spiegato a parole: "calcolare la probabilit√† dell'evento di $A$ con la condizione di $B$"

:::def
Dato $(\Omega, \mathbb P)$ e $B$ _evento_ definisco probabilit√† condizionata a $B$. Indico con $\mathbb P(* | B)$ la seguente funzione:

$$
\mathbb P(* |B): \mathbb P(\Omega) \longrightarrow \Omega \qquad A -> \mathbb P(A | B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

a patto che:

$$
\frac{
\mathbb P(B)}{0}
$$

:::

ü™∂ probabilit√† condizionata $\mathbb P(A‚à£B)$, che si legge ‚Äúprobabilit√† di $A$ condizionata da $B$‚Äù

Continuando l'esempio:

$P(A \cap B) = \frac{\#A \cap B}{\# \Omega} = \frac{1}{36}$

$A \cap B = \{ (6,3) \}$

$\mathbb P(B) = \frac{6}{36}$

$\mathbb (A|B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)} = \frac{1}{6}$

$C =$ "il primo dado ha fatto 1"

$$
\mathbb P(A |C) = \frac{A \cap C}{\mathbb P} = \frac{0}{\frac{6}{36}} = 0
$$

---

## La probabilit√† condizionata √® ben definita?

Per scoprirlo dobbiamo vedere che le 3 regole della probabilit√† valgano.

1. _La $\mathbb P(A | B) \geq 0$_? $\forall A \mathbb P(A | B) = \frac{\mathbb P(A unito b)}{\mathbb P(B) \geq 0}$

2. $\mathbb P(\Omega | B) = 1$ (la somma di tutte le partizioni risulter√† 1)?<br/>
   $\mathbb P(\Omega | B)= \frac{\Omega \cap B}{\mathbb P(B)} = \frac{\mathbb P(B)}{\mathbb P(B)} = 1$

3. $A_1$ e $A_2$ con $A_2$ intersecato $A_1 = \emptyset$ (la legge dei singoletti) $\mathbb P(A_1 \cap A_2 | B) = \mathbb P(A_1 | B) + \mathbb P(a_2 | B)$? Dato che $A_1$ e $A_2$ sono disgiunti anche l'intersezione con $\mathbb B$ sar√† disgiunta.

Il punto √® che prima avevo $(\Omega, \mathbb P)$ ho definito una nuova misura di probabilit√† su $\Omega$ che ho chiamato $\mathbb P(* | B)$

osservazione:

$$
\mathbb P(A | B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

$$
\mathbb P(B) \cdot \mathbb P(A | B) = \mathbb P(B) \cdot \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

$$
(*)\qquad \mathbb P(A \cap B) = \mathbb P(A | B) \cdot \mathbb P(B)
$$
