---
capitolo: 3
layout: "../../../layouts/PostLayoutV2.astro"
---

# Media varianza e momenti di variabili aleatorie discrete

- $X$ va discreta PMF
  1. $Imm(X)$
  2. $P_X(t) \quad \forall k \in Imm(X)$
  3. $\mathbb P(X = k)$

Introduciamo oggetti che riassumono/ comprimono l'infomrazione contenuta nella PMF.

:::def
Chiamo media della Va discrata $X$ la variabile discreta la seguente quantità:

$\mathbb E(X) = \sum_{k\in Imm(X)} k \cdot P_x(k) = \sum_{k \in Imm(X)} k \cdot \mathbb P(X=k)$
:::

es: $X\sim$ Bernulli(p)
$Imm(X) = \{ 0.1 \}$

$P_x(0) = 1 - p$

$P_x(1) = p$

$\mathbb E(X) = \sum_{k \in Imm(X)} k \cdot P_x(k) = 0 \cdot P_x(0) +1 \cdot P_x(1) = \\ 0 \cdot \mathbb P(X = 0) + 1 \cdot \mathbb P(X = 1)$

È una media pesata

$$
\sum_{k \in Imm(X)} k\cdot \mathbb P(X=k)
$$

$k$ sono i valori di cui faccio la media

$\mathbb P(X=k)$ sono i pesi della media

Es guardo $X$ come una ruota della fortuna

$a_1 \quad P_x(a_1) = p_1 = \mathbb P(X = a_1)$

$a_2 \quad P_x(a_2) = p_2 = \mathbb P(X = a_2)$

...

...

Faccio girare la ruota della forutna $k$ volte (tante)

es: $a_1, a_3, a_{10}, a_7, ....$

Una volta fatta la media aritmetica dei valori ottenuti:

$$
\frac{a_1 \cdot k_1 + a_2 \cdot k_2 + ... + a_n \cdot k_n}{k}
$$

$k$ quante volte ho ottenuto la $a$

$$
a_1 \cdot \frac{k_1}{K} + a_2 \cdot \frac{k_2}{K} + ... + a_n \cdot \frac{k_n}{k}
$$

le $a \in Imm(X)$ valori assunti

$\frac{k_n}{K}$ frequenze relative di occorenze degli $a_i$

$$
k \rightarrow + \infty \quad \frac{k_i}{K} \approx pi = \mathbb P(X = a_i)\\
\approx \frac{a_1 \cdot p_1 + a_2 \cdot p_2 + ... + a_n \cdot p_n}{\mathbb E(X)}
$$

la $\mathbb E(X)$ è la media dei valori assunti dalla V.a. se immagino di "lanciarla" $K$ volte con $K \rightarrow + \infty$

---

:::def
Chiamo vallanza della v.a. discreta $X$ la seguente quantità

$Van(X) = \mathbb E[(x-\mathbb E(X))^2]$

$(X- \mathbb E(X))^2$
:::

La vairanza è la media dello scarto quadratico della v.a. $X$ mi dice quanto mediamenta la v.a. $X$ scarta (al quadrato) della media (si allontana)

Come si calcola?

Se uso la Def data dovrei calcolare la $\mathbb E$ della v.a. ma non so che PMf ha.

$\mathbb E(y) = \sum_{y \in Imm(y)} y \cdot \mathbb P(Y = y)$

teo: se $Y = g(X)$

$$
\mathbb E(Y) = \sum_{k \in Imm(X)} g(k) \cdot P_x(k) = \\
\sum_{k \in Imm(X)} g(k) \cdot \mathbb P(X = k)
$$

es: $X \sim$ Bernulli(p)

$\mathbb E(X) = p$

$Van(X) = \mathbb E((X-\mathbb E(x)^2) = \\ g(0) \cdot P_x(1) + g(1) \cdot P_x(1) = (0-p)^2 \cdot ( 1 - p) + (1-p)^2 \cdot p = p \cdot (1-p)$

$Van(X)$ e $\mathbb E(X)$ non hanno la stessa unità di misura

Deviazione standard: $stdev(C) = \sqrt{Va(X)}$

Teorema: $E[y] = \mathbb E[g \circ X] = \sum_{x \in Imm(X)}g(x)\cdot P_x(x)$

$Var(x) \geq 0$ perchè $Var(X) = \sum_{x\in Imm(X)} (x-\mathbb E(X))^2 \cdot P_x(x)$

$Var(x) = 0 \quad (x-\mathbb E(x))^2 = 0 \quad \forall x \in Imm(X) \\ x-\mathbb E(x) = 0 \\ x = \mathbb E(x)$  
$X$ prende sono un valore  
$Imm(X) = \{ c \} \\ P_x(c) = 1 \\ \mathbb E(x) = 1 \cdot c = c$  
$X$ è una funzione costante

---

## Momento

:::def
Chiamo momento di ordine $k$ della v.a. $X$ la seguente quantità:  
$w_k(X) = \mathbb E(X^k)$
:::

$X^k = f: \R \rightarrow \R \\ x \mapsto x^k$

esempio: Calcolo il momenti di ordine $2$ di $X \sim Bernulli(p) \\ \mathbb E(X)=p \\
Var(X)= p \cdot (1-p)\\
m_2(X)=\mathbb E(X^2) = \sum_{x\in Imm(X)}f(x) \cdot P_x(x)=\\ f(x) \cdot P_x(0) + f(1)\cdot P_x(1) = \\
0^2 \cdot \mathbb P(X=0) + 1^2 \cdot \mathbb P(X=1) = p$

$m_3(X) = \mathbb E(X^3)= 0^3 \cdot (1-p) + 1^3 \cdot p = p$

## Proprietà di media varianza

1. $\mathbb E(aX + bY) = a \cdot \mathbb E(X) + b \cdot \mathbb E(Y)$  
   $X,Y$ v.a.  
   $a,b \in \R$

2. $Var(X) = \mathbb E(X^2) - [\mathbb E(X)]^2$
3. $Var(a\cdot X+b) = a^2 \cdot Var(X) \\ X$ v.a. e $a,b \in \R$ la varianza è invariante per traslazioni, la varianza è quadratica nelle costanti moltiplicative.

### Media e varianza della v.a. discrete note

- $X \sim Bernulli(p) \\ \mathbb E(X) = p \\ Var(X) = p \cdot (1-p)$
- $X \sim Binomiale(n,p) \\ \mathbb E(X) = n\cdot p \\ Var(X) = n \cdot p \cdot (1-p)$
- $X\sim Geom(p) \\ \mathbb E(X) = \frac{1}{p} \\ Var(X) = \frac{(1-p)}{p^2}$
- $X \sim Poisson(\lambda)\\\mathbb E(X)= \lambda \\ Var(X) = \lambda$

## Esercizi

1.  Se $\mathbb E(X) = 2, \mathbb E(X^2) = 8$ calcolare  
     - $\mathbb E[(2+4X)^2]$ - $\mathbb E[  X^2+ (X+1)^2]$ - $Var(X)$
    \*\*\* - $\mathbb E[(x+4X)^2] = \mathbb E[a+16X^2+16X] = \\ \mathbb E(4)+ \mathbb E(16X^2) + \mathbb E(16X^2)+ \mathbb E(16X) \\ = 4 +16 \mathbb E(X^2) + 16 \cdot \mathbb E(X) = \\ 4+16 \cdot 8 + 16 \cdot 2 = 164$  
     - $\mathbb E[X^2+(X+1)^2]= \\ \mathbb E[X^2+X^2+1+2X]= \mathbb E[2X^2+2X+1] \\ = \mathbb E(2X^2) + \mathbb E(2X) + \mathbb E(1) = \\ = 2 \cdot \mathbb E(X^2) + 2 \cdot E(X)+1 = \\ 2 \cdot 8 + 2 \cdot 2 +1 =21$  
     - $Var(X)= $\mathbb E(X^2)- [\mathbb E(X)]^2= \\ 
    8-2^2=8-4=4$

1.  Sia $X$ va con PMF seguente:  
     $Imm(X) = \{ 1,2,3,4 \}$
    $P_x(x) = \begin{cases}
  \frac{1}{4} & x = 1,2 \\
  \frac{1}{3} & x=3\\
  \frac{1}{6} & x=4
  \end{cases}$
    Calcolare $\mathbb E(X)$ e $Var(X) \\
  \mathbb E(X) = \sum_{x\in Imm(X)} x \cdot P_x(x) = \sum_{x\in Imm(x)}x \cdot \mathbb P(X = x) = \\
1\cdot \mathbb P(X = 1) + 2 \cdot \mathbb P(X=2)+3 \cdot \mathbb P(X = 3) + 4 \cdot \mathbb P(X= 4)\\
=\frac{1}{4} + \frac{1}{2} + 1 + \frac{2}{3}= \frac{29}{12}
\\Var(X) = \mathbb E((x-\mathbb E(X))^2) \\ = \sum\_{x \in Imm(X)}(x-\mathbb E(X)^2)\cdot P_x(X) = \\
(1 - \frac{29}{2})^2\cdot \frac{1}{4}+ (2-\frac{29}{12})^2 \cdot \frac{1}{4}+ (3-\frac{29}{12}^3) \cdot \frac{1}{3} + (4-\frac{29}{12})^2 \cdot \frac{1}{6} = 1.076$

1.  Sia $X\sim Binomiale(n,p)$ con $\mathbb E(X) = 7$ e $Var(X) = 2.1$ calcolare:  
     $\mathbb P(X=4) \\ \mathbb P(X > 12)$  
     $P(X=4) = P_X(4)$  
     n? e p? devo usare $\mathbb E(X)=7 \quad Var(X)=2.1 \\ \mathbb E(X) = n \cdot p \\ Var(X) = n \cdot p \cdot (1-p) \\ \begin{cases}
n \cdot p = 7 \\
n \cdot p(1-p) = 2.1
\end{cases}\\
7(1-p)=2.1\\
(1-p)=\frac{2.1}{7} \\
1-\frac{2.1}{7}= p \\
1 - \frac{21}{10} \cdot \frac{1}{7}= p \\
1 - \frac{3}{10} = p \rightarrow p = \frac{7}{10}\\
n \cdot \frac{7}{10} = 7 \\
n = 7 \cdot \frac{10}{7} \\
n = 10
$  
     $X \sim bernulliana(10, \frac{7}{10})$

- $\mathbb P(X = 4) = P_X(4) = \binom{n}{4}p^4(1-p) = $ uso R e ottengo `binom(4,10,7/10)` = 0.03675 = 0.0368
  - $\mathbb P(X > 12) = 0$

1.  Lancio 5 volte una moeta equa e sono interessato al numero di teste e al numero di croci  
    $X$: numero di teste  
    $Y$: numero di croci  
    $P(X==3)$  
    $\mathbb P(\{ X=3 \} \cap \{ Y=1 \}) = \mathbb P(X = 3, Y = 1)=0$  
    $0$ significa che non ci sono elmeenti di $\Omega$ che vengono mandati in $(3,1)$  
    $(x,y)(w) \rightarrow (X(w),Y(w)) \\ (x,y): \Omega \rightarrow \R^2 \\ \mathbb P(X=3, Y=1)= \mathbb P((X,Y)=(3,1)) = \mathbb P(\emptyset) = 0$
